from collections import deque
from enum import Enum
from typing import Any

from pydantic import BaseModel, ConfigDict, Field, computed_field
from typing_extensions import Self

from src.infra.config import get_config


class AgentActionIntent(str, Enum):
    """
    Enumeration of possible agent action intents.
    These are the various intents an agent can select for their turn.
    """

    IDLE = "idle"
    CONTINUE_COLLABORATION = "continue_collaboration"
    PROPOSE_IDEA = "propose_idea"
    ASK_CLARIFICATION = "ask_clarification"
    PERFORM_DEEP_ANALYSIS = "perform_deep_analysis"
    CREATE_PROJECT = "create_project"
    JOIN_PROJECT = "join_project"
    LEAVE_PROJECT = "leave_project"
    SEND_DIRECT_MESSAGE = "send_direct_message"


class AgentState(BaseModel):
    """
    Represents the complete internal state of an agent.
    This model is used for the persistent state of an agent instance.
    """

    model_config = ConfigDict(extra="forbid")
    agent_id: str
    name: str
    role: str
    steps_in_current_role: int = 0
    mood: str = "neutral"
    descriptive_mood: str = "neutral"  # More detailed mood description
    ip: float  # Will be initialized from config in BaseAgent
    du: float  # Will be initialized from config in BaseAgent
    # Add collective metrics tracking
    collective_ip: float | None = None  # Total IP across all agents in simulation
    collective_du: float | None = None  # Total DU across all agents in simulation
    relationships: dict[str, float] = Field(
        default_factory=dict
    )  # Maps agent_id to relationship score
    short_term_memory: deque[dict[str, Any]] = Field(
        default_factory=deque
    )  # Queue of memory entries
    goals: list[dict[str, Any]] = Field(
        default_factory=list
    )  # List of goals/objectives for this agent
    agent_goal: str = Field(
        default="Contribute to the simulation as effectively as possible."  # High-level goal for the agent # noqa: E501
    )
    role_history: list[tuple[int, str]] = Field(
        default_factory=list
    )  # List of (step, role) tuples
    mood_history: list[tuple[int, str]] = Field(
        default_factory=list
    )  # List of (step, mood) tuples
    ip_history: list[tuple[int, float]] = Field(default_factory=list)  # List of (step, ip) tuples
    du_history: list[tuple[int, float]] = Field(default_factory=list)  # List of (step, du) tuples
    relationship_history: list[tuple[int, dict[str, float]]] = Field(
        default_factory=list
    )  # List of (step, relationships) tuples
    project_history: list[tuple[int, str | None]] = Field(
        default_factory=list
    )  # List of (step, project_id) tuples
    projects: dict[str, Any] = Field(default_factory=dict)  # Maps project_id to project details

    # LLM client for generating summaries and other memory operations
    llm_client: Any | None = None

    # Temporary state for agent operations
    last_thought: str | None = None  # Last thought generated by the agent
    last_clarification_question: str | None = None  # Last clarification question asked
    last_clarification_downgraded: bool = False  # Flag to indicate if clarification was downgraded

    # Project affiliation for Group Affiliation Mechanism
    current_project_id: str | None = None  # Current project ID (if any)
    current_project_affiliation: str | None = None  # Name of current project for prompting

    # Message and action counters
    messages_sent_count: int = 0
    messages_received_count: int = 0
    actions_taken_count: int = 0
    last_message_step: int | None = None
    last_action_step: int | None = None

    # Available actions and action intents for this agent
    available_action_intents: list[str] = Field(default_factory=list)

    # Step counter for tracking simulation steps
    step_counter: int = 0

    # Configuration fields (optional, could be passed separately, but useful to have here)
    # These should likely be set during initialization and not change
    max_short_term_memory: int  # Will be initialized from config in BaseAgent
    short_term_memory_decay_rate: float  # Will be initialized from config in BaseAgent
    relationship_decay_rate: float  # Will be initialized from config in BaseAgent
    min_relationship_score: float  # Will be initialized from config in BaseAgent
    max_relationship_score: float = 1.0
    mood_decay_rate: float  # Will be initialized from config in BaseAgent
    mood_update_rate: float  # Will be initialized from config in BaseAgent
    ip_cost_per_message: float  # Will be initialized from config in BaseAgent
    du_cost_per_action: float  # Will be initialized from config in BaseAgent
    role_change_cooldown: int  # Will be initialized from config in BaseAgent
    role_change_ip_cost: float = Field(default_factory=lambda: get_config("ROLE_CHANGE_IP_COST"))

    # New relationship dynamics parameters
    positive_relationship_learning_rate: float = Field(
        default_factory=lambda: get_config("POSITIVE_RELATIONSHIP_LEARNING_RATE")
    )
    negative_relationship_learning_rate: float = Field(
        default_factory=lambda: get_config("NEGATIVE_RELATIONSHIP_LEARNING_RATE")
    )
    targeted_message_multiplier: float = Field(
        default_factory=lambda: get_config("TARGETED_MESSAGE_MULTIPLIER")
    )

    # Memory consolidation tracking
    last_level_2_consolidation_step: int = 0

    # --- Mood Management (Derived) ---
    @computed_field
    def mood_value(self) -> float:
        """
        Returns a numerical representation of the agent's mood.
        This can be used for calculations or simpler comparisons.
        """
        mood_mapping = {
            "very_positive": 1.0,
            "positive": 0.5,
            "neutral": 0.0,
            "negative": -0.5,
            "very_negative": -1.0,
        }
        return mood_mapping.get(self.mood, 0.0)  # Default to neutral if mood is somehow invalid

    def add_memory(self: Self, step: int, memory_type: str, content: str) -> None:
        """
        Adds a memory to the agent's short-term memory deque.

        Args:
            step (int): The simulation step in which the memory occurred
            memory_type (str): Type of memory (e.g., 'thought', 'message_sent', 'message_received')
            content (str): The content of the memory
        """
        memory_entry = {"step": step, "type": memory_type, "content": content}
        self.short_term_memory.append(memory_entry)

    def update_mood(self: Self, new_mood: str) -> None:
        """
        Updates the agent's mood.

        Args:
            new_mood (str): The new mood to set.
        """
        if isinstance(new_mood, int):
            # Convert integer mood to string to avoid Pydantic warnings
            new_mood = str(new_mood)

        self.mood = new_mood
        # Also update descriptive mood to match for consistency
        self.descriptive_mood = new_mood
        self.mood_history.append((self.step_counter, new_mood))

    def __init__(self: Self, **data: object) -> None:
        super().__init__(**data)
        self.max_short_term_memory = self.max_short_term_memory
        self.short_term_memory_decay_rate = self.short_term_memory_decay_rate
        self.relationship_decay_rate = self.relationship_decay_rate
        self.min_relationship_score = self.min_relationship_score
        self.max_relationship_score = self.max_relationship_score
        self.mood_decay_rate = self.mood_decay_rate
        self.mood_update_rate = self.mood_update_rate
        self.ip_cost_per_message = self.ip_cost_per_message
        self.du_cost_per_action = self.du_cost_per_action
        self.role_change_cooldown = self.role_change_cooldown
        self.role_change_ip_cost = self.role_change_ip_cost
        self.positive_relationship_learning_rate = self.positive_relationship_learning_rate
        self.negative_relationship_learning_rate = self.negative_relationship_learning_rate
        self.targeted_message_multiplier = self.targeted_message_multiplier
        self.step_counter += 1

    # Add methods to update collective metrics
    def update_collective_metrics(self: Self, collective_ip: float, collective_du: float) -> None:
        """
        Updates the agent's perception of collective IP and DU metrics.

        Args:
            collective_ip (float): Total influence points across all agents
            collective_du (float): Total data units across all agents
        """
        self.collective_ip = collective_ip
        self.collective_du = collective_du

    def update_ip(self: Self, new_ip: float) -> None:
        self.ip = new_ip
        self.ip_history.append((self.step_counter, new_ip))

    def update_du(self: Self, new_du: float) -> None:
        self.du = new_du
        self.du_history.append((self.step_counter, new_du))

    def update_role(self: Self, new_role: str) -> None:
        self.role = new_role
        self.role_history.append((self.step_counter, new_role))

    def update_project(self: Self, project_id: str | None) -> None:
        self.current_project_id = project_id
        self.project_history.append((self.step_counter, project_id))

    def update_step_counter(self: Self) -> None:
        self.step_counter += 1

    def update_short_term_memory(self: Self, memory: dict[str, Any]) -> None:
        self.short_term_memory.append(memory)

    def update_goals(self: Self, goals: list[dict[str, Any]]) -> None:
        self.goals.extend(goals)

    def update_messages_sent_count(self: Self) -> None:
        self.messages_sent_count += 1

    def update_messages_received_count(self: Self) -> None:
        self.messages_received_count += 1

    def update_actions_taken_count(self: Self) -> None:
        self.actions_taken_count += 1

    def update_last_message_step(self: Self, step: int) -> None:
        self.last_message_step = step

    def update_last_action_step(self: Self, step: int) -> None:
        self.last_action_step = step

    def update_available_action_intents(self: Self, intents: list[str]) -> None:
        self.available_action_intents.extend(intents)

    def update_last_clarification_question(self: Self, question: str | None) -> None:
        self.last_clarification_question = question

    def update_last_clarification_downgraded(self: Self, downgraded: bool) -> None:
        self.last_clarification_downgraded = downgraded

    def update_relationship_history(
        self: Self, step: int, relationships: dict[str, float]
    ) -> None:
        self.relationship_history.append((step, relationships))

    def update_ip_history(self: Self, step: int, ip: float) -> None:
        self.ip_history.append((step, ip))

    def update_du_history(self: Self, step: int, du: float) -> None:
        self.du_history.append((step, du))

    def update_role_history(self: Self, step: int, role: str) -> None:
        self.role_history.append((step, role))

    def update_project_history(self: Self, step: int, project_id: str | None) -> None:
        self.project_history.append((step, project_id))

    def update_current_project_affiliation(self: Self, affiliation: str | None) -> None:
        self.current_project_affiliation = affiliation

    def update_current_project_id(self: Self, project_id: str | None) -> None:
        self.current_project_id = project_id

    def apply_relationship_decay(self: Self, decay_factor: float) -> None:
        """
        Applies exponential decay to all relationship scores.
        Each score is multiplied by (1 - decay_factor) and clamped to the valid range.
        Args:
            decay_factor (float): The decay factor to apply (e.g., 0.01 for 1% decay per step).
        """
        for agent_id, score in self.relationships.items():
            decayed = score * (1 - decay_factor)
            decayed = max(self.min_relationship_score, min(self.max_relationship_score, decayed))
            self.relationships[agent_id] = decayed
