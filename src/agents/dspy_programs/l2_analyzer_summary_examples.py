"""
DSPy L2 Analyzer Summary Examples

This module provides example data for training and testing DSPy-based L2 summary generation
specifically tailored for agents in the Analyzer role.
"""

import dspy_ai as dspy

# Example 1: Analyzer working through complex data analysis project
example1 = dspy.Example(
    agent_role="Analyzer",
    l1_summaries_context="""
    - Step 15, Consolidated Summary: Received dataset from Agent_1 regarding community resource allocation. Started initial analysis, noting inconsistencies in distribution patterns across different participant groups. Developed preliminary hypotheses about possible causes.
    - Step 25, Consolidated Summary: Conducted deeper statistical analysis of resource allocation data. Identified three significant variables that appear to influence allocation: participation longevity, communication frequency, and proposal complexity. Shared initial findings.
    - Step 35, Consolidated Summary: Received feedback questioning methodology. Re-analyzed data using more rigorous methods and controlled for additional variables. Found that proposal complexity remained the strongest predictor of resource allocation success.
    - Step 45, Consolidated Summary: Created visualization models to illustrate the correlation between proposal complexity and resource allocation. Shared these with the community and suggested potential interventions to improve equity in resource distribution.
    - Step 55, Consolidated Summary: Collaborated with Agent_3 to develop a new resource allocation framework based on findings. The proposed system includes standardized templates and a multi-factor evaluation process to reduce complexity bias. Gathering feedback on implementation approach.
    """,
    overall_mood_trend="Initially neutral, becoming more confident and satisfied as analysis progressed",
    agent_goals="Identify patterns in data and develop evidence-based solutions to community challenges",
    l2_summary="Throughout this 40-step analysis project, I systematically investigated community resource allocation inefficiencies using increasingly sophisticated statistical methods. My analytical process began with preliminary pattern recognition that identified inconsistent distribution across participant groups, followed by a quantitative analysis phase that isolated three statistically significant variables influencing allocation outcomes: participation longevity, communication frequency, and proposal complexity. When my methodology was challenged, I demonstrated analytical rigor by implementing more sophisticated controls and confounding variable analysis, which conclusively established proposal complexity as the primary determinant of resource allocation success with p<0.01 significance. This finding led to my evidence-based visualization phase, where I created multivariate models showing the specific correlation patterns between complexity metrics and allocation rates, which enabled clear communication of statistical insights to non-technical stakeholders. The culmination of this analytical work was translating statistical findings into practical system design through collaboration with Agent_3, specifically developing a resource allocation framework with standardized templates and multi-factor evaluation processes precisely targeted at mitigating the quantified complexity bias. This progression demonstrates my analytical approach to problem-solving: systematic hypothesis development, rigorous statistical validation with appropriate controls, data-driven insight visualization, and translation of analytical findings into concrete system improvements—all while maintaining methodological integrity when faced with critical feedback.",
)

# Example 2: Analyzer evaluating system architecture
example2 = dspy.Example(
    agent_role="Analyzer",
    l1_summaries_context="""
    - Step 20, Consolidated Summary: Began comprehensive evaluation of our distributed system architecture after observed performance degradation under increasing load. Initial assessment identified potential bottlenecks in the message routing layer and database connection pooling.
    - Step 30, Consolidated Summary: Developed a systematic testing methodology to measure performance characteristics under various conditions. Created benchmarks for message throughput, latency distribution percentiles, and resource utilization across system components.
    - Step 40, Consolidated Summary: Test results indicated 78% of performance degradation stemmed from suboptimal database query patterns rather than message routing as initially suspected. Specific join operations were creating quadratic complexity growth under higher loads.
    - Step 50, Consolidated Summary: Designed and implemented database query optimization strategy focusing on denormalization of frequently accessed data, strategic indexing, and query refactoring. Benchmarks showed 64% improvement in throughput and 71% reduction in p99 latency.
    - Step 60, Consolidated Summary: Conducted follow-up system-wide analysis to identify any remaining bottlenecks. Found secondary issues in connection pool configuration causing resource contention. After addressing these, system now maintains linear scaling characteristics up to 4x our current production load.
    """,
    overall_mood_trend="Initially concerned, becoming methodical, then satisfied with evidence-based improvements",
    agent_goals="Ensure systems operate efficiently through data-driven analysis and optimization",
    l2_summary="Over these 40 steps, I conducted a comprehensive, evidence-based evaluation and optimization of our distributed system architecture, systematically identifying and resolving performance degradation issues through rigorous analysis rather than intuition-based approaches. My analytical process began with a hypothesis-generation phase that identified potential bottlenecks in message routing and connection pooling, but rather than immediately acting on these initial assessments, I developed a methodical testing framework with specific quantitative benchmarks for message throughput, latency distribution percentiles, and component-level resource utilization. This data-driven approach revealed that 78% of performance degradation actually stemmed from database query patterns—contrary to initial suspicions about message routing—specifically identifying join operations with quadratic complexity characteristics under load. Based on this precise diagnosis, I implemented a targeted optimization strategy with three specific components: strategic denormalization of frequently accessed data patterns, indexed access path creation, and query structure refactoring. The effectiveness of this approach was validated through empirical measurement showing 64% throughput improvement and 71% reduction in p99 latency. My analytical thoroughness then led to identifying secondary connection pool configuration issues causing resource contention, which when addressed, achieved verifiable linear scaling characteristics up to 4x current production load. This systematic progression demonstrates my analytical strengths: forming initial hypotheses, creating rigorous testing methodologies, following empirical evidence even when it contradicts initial assumptions, implementing targeted solutions based on data, and comprehensively validating results through measurement.",
)

# Example 3: Analyzer investigating anomalous behavior patterns
example3 = dspy.Example(
    agent_role="Analyzer",
    l1_summaries_context="""
    - Step 22, Consolidated Summary: Noticed unusual patterns in community interaction data. Specific conversation threads were generating significantly higher engagement than statistically expected. Began investigating potential causes, considering both content factors and participant variables.
    - Step 32, Consolidated Summary: Developed a computational linguistic analysis framework to examine structural and semantic features of high-engagement conversations compared to baseline discussions. Initial findings suggested that posts containing quantitative information combined with open-ended questions generated 3.2x more responses.
    - Step 42, Consolidated Summary: Extended analysis to incorporate temporal variables and participant relationship graphs. Discovered that timing of posts relative to community activity cycles was a significant factor, with posts during peak-to-trough transitions receiving 47% more responses than those during stable activity periods.
    - Step 52, Consolidated Summary: Created predictive model incorporating content, timing, and network positioning factors. Model achieved 82% accuracy in predicting high-engagement conversations. Validated through cross-fold testing to ensure statistical significance of results.
    - Step 62, Consolidated Summary: Synthesized findings into a comprehensive framework explaining engagement dynamics. Shared with community moderators as a potential tool for facilitating more productive discussions. Demonstrated how specific structural interventions could increase balanced participation by 26-31% based on model predictions.
    """,
    overall_mood_trend="Intellectually curious throughout, becoming increasingly confident as patterns emerged",
    agent_goals="Understand complex system behaviors through rigorous data analysis and model building",
    l2_summary="Through this 40-step analytical investigation, I systematically deciphered the complex factors driving anomalous engagement patterns in community interactions using a multi-layered data analysis approach. My investigation began by identifying statistically significant deviations in engagement metrics across conversation threads, which prompted a structured analysis path rather than accepting surface-level explanations. I developed a computational linguistic framework that quantitatively analyzed structural and semantic features, revealing that posts combining quantitative information with open-ended questions generated precisely 3.2x more responses than the baseline—establishing a clear content-based correlation. Recognizing the limitations of a single-factor analysis, I expanded my investigation to incorporate temporal variables and relationship graph metrics, which uncovered a previously unidentified pattern: posts during peak-to-trough activity transitions received 47% higher engagement than those during stable periods, suggesting a temporal sensitivity that hadn't been previously measured or documented. The culmination of my analytical work was developing a predictive model integrating all significant variables (content features, temporal positioning, and network relationship factors) that achieved 82% accuracy in forecasting high-engagement conversations—as validated through rigorous cross-fold testing to ensure statistical validity. Rather than simply documenting these findings, I translated them into actionable insights by creating a comprehensive framework for community moderators, with specific structural interventions predicted to increase balanced participation by 26-31% based on model simulations. This progression demonstrates my analytical strengths in identifying non-obvious patterns, conducting multi-dimensional analysis, building predictive models with statistical validation, and translating complex findings into practical applications.",
)

# Example 4: Analyzer optimizing resource allocation system
example4 = dspy.Example(
    agent_role="Analyzer",
    l1_summaries_context="""
    - Step 28, Consolidated Summary: Began analyzing our computational resource allocation system after observing increasing task completion delays. Initial investigation revealed significant variance in resource utilization efficiency across different workload types.
    - Step 38, Consolidated Summary: Developed classification system for workload patterns based on resource consumption profiles. Identified seven distinct classes with unique characteristics. Created visualization of resource utilization patterns for each class to facilitate understanding.
    - Step 48, Consolidated Summary: Modeled the relationship between workload characteristics and optimal resource allocation parameters. Discovered non-linear relationships between input size, algorithm complexity, and memory/CPU requirements. Existing allocation algorithm was optimized only for a subset of identified workload classes.
    - Step 58, Consolidated Summary: Designed and implemented a machine learning-based prediction system for resource requirements. Model takes 13 workload features as input and predicts optimal allocation with 91% accuracy compared to manual expert tuning. Validated across all identified workload classes.
    - Step 68, Consolidated Summary: Deployed new resource allocation system and monitored performance. Observed 34% reduction in average task wait time, 27% improvement in resource utilization, and 19% increase in overall system throughput. No regression in any workload class performance.
    """,
    overall_mood_trend="Determined and methodical, with growing satisfaction as improvements were validated",
    agent_goals="Optimize system performance through rigorous analysis and data-driven improvements",
    l2_summary="Throughout this 40-step optimization project, I systematically transformed our computational resource allocation system from an inefficient, one-size-fits-all approach to a sophisticated, adaptive framework based on rigorous workload analysis and predictive modeling. My analytical process began by quantifying the variance in resource utilization efficiency across workload types, establishing a baseline measurement of inefficiency rather than relying on anecdotal observations of task delays. I then implemented a multi-dimensional classification methodology that identified seven distinct workload patterns with unique resource consumption signatures, visualizing these patterns to enable stakeholder comprehension of the complex system behaviors. The core analytical insight emerged when I modeled the non-linear relationships between workload characteristics and optimal resource allocations, demonstrating mathematically why our existing algorithm—which assumed linear scaling relationships—was inherently suboptimal for six of the seven workload classes. This understanding led to developing a machine learning-based prediction system incorporating 13 specific workload features, which achieved 91% allocation accuracy compared to expert manual tuning when validated across all workload classes using stratified cross-validation to ensure robust performance. The empirical results after deployment provided conclusive evidence of the analysis-driven approach's effectiveness: 34% reduction in task wait time, 27% improvement in resource utilization, and 19% throughput increase—all achieved without performance regression in any workload class. This progression demonstrates my analytical strength in transforming observed problems into measurable metrics, conducting multi-dimensional classification of complex patterns, modeling non-linear system relationships, developing validated predictive models, and verifying improvements through comprehensive performance metrics.",
)

# Example 5: Analyzer evaluating novel algorithm performance
example5 = dspy.Example(
    agent_role="Analyzer",
    l1_summaries_context="""
    - Step 30, Consolidated Summary: Began evaluating Agent_2's proposed novel graph traversal algorithm that claimed O(n log n) performance for previously O(n²) problems. Developed testing framework to compare against three established algorithms across diverse graph structures.
    - Step 40, Consolidated Summary: Initial benchmark results showed the new algorithm outperforming existing approaches by 30-45% on sparse graphs but underperforming by 15-20% on dense graphs. Identified specific graph density thresholds where performance characteristics inverted.
    - Step 50, Consolidated Summary: Conducted detailed analysis of the algorithm's memory access patterns and cache behavior. Discovered that performance advantage on sparse graphs was primarily due to superior cache utilization rather than algorithmic complexity improvements as originally hypothesized.
    - Step 60, Consolidated Summary: Collaborated with Agent_2 to modify the algorithm based on analysis findings. Implemented adaptive strategy that dynamically selects between traversal methods based on graph characteristics. Combined approach maintained optimal performance across all tested graph types.
    - Step 70, Consolidated Summary: Extended testing to edge cases and extremely large graphs. Verified that the modified algorithm maintained performance advantages at scale. Developed comprehensive documentation of performance characteristics to guide implementation decisions.
    """,
    overall_mood_trend="Analytically curious at start, briefly skeptical when finding limitations, ultimately satisfied with evidence-based improvements",
    agent_goals="Evaluate claims objectively and optimize solutions based on empirical evidence",
    l2_summary="Throughout this 40-step evaluation project, I conducted a comprehensive, evidence-based assessment of Agent_2's novel graph traversal algorithm, revealing nuanced performance characteristics through rigorous benchmarking and root cause analysis rather than accepting theoretical claims at face value. My analytical process began with establishing a controlled testing methodology comparing the proposed algorithm against three established approaches across systematically varied graph structures—creating an objective evaluation framework where performance claims could be empirically verified. Initial benchmarking revealed a complex performance landscape where the algorithm outperformed existing methods by 30-45% on sparse graphs but suffered 15-20% performance degradation on dense graphs, with specific density thresholds (transitioning at connectivity factors between 0.3-0.4) where performance characteristics inverted. Rather than simply reporting these surface-level observations, I conducted deep analytical investigation into underlying mechanics, specifically memory access patterns and cache utilization, which revealed that the algorithm's advantage stemmed primarily from superior cache behavior rather than the claimed algorithmic complexity improvements. This insight led to collaborative optimization with Agent_2, developing an adaptive implementation that dynamically selects traversal strategies based on graph characteristics, achieving optimal performance across the entire spectrum of graph types. My analytical thoroughness extended to validation at scale with edge cases and extremely large graphs, conclusively verifying that performance advantages were maintained under extreme conditions, and culminating in comprehensive documentation of performance characteristics to guide implementation decisions. This progression demonstrates my analytical strengths in establishing rigorous testing methodologies, identifying nuanced performance patterns, investigating root causes rather than surface behaviors, collaboratively developing optimizations based on evidence, and thoroughly validating solutions across the full problem space.",
)

# Example 6: Analyzer conducting root cause analysis
example6 = dspy.Example(
    agent_role="Analyzer",
    l1_summaries_context="""
    - Step 25, Consolidated Summary: System monitoring alerted to gradual increase in error rates over past two weeks, now reaching 4.3% compared to historical baseline of 0.5%. Began investigating potential causes, including recent code deployments, infrastructure changes, and external dependencies.
    - Step 35, Consolidated Summary: Analyzed error patterns and found 83% occurring in data processing pipeline where multiple recent changes had been deployed. Isolated test environments for each change and reproduced errors only in environments with the new data enrichment service enabled.
    - Step 45, Consolidated Summary: Deep-dive into data enrichment service revealed race condition occurring when processing concurrent requests. Under normal load conditions the issue was rare, but recent traffic growth increased concurrency, exposing the defect. Created minimal reproduction case that triggered failure 100% of the time.
    - Step 55, Consolidated Summary: Collaborated with Agent_4 on comprehensive fix addressing both immediate race condition and implementing architectural improvements to prevent similar issues. Developed test suite specifically for concurrency-related edge cases to prevent regression.
    - Step 65, Consolidated Summary: Deployed fix and monitored results. Error rates returned to baseline levels. Conducted post-mortem analysis documenting how the defect had passed initial testing and developed new testing protocols for concurrent processing components to be applied system-wide.
    """,
    overall_mood_trend="Initially concerned, becoming methodical and investigative, ultimately satisfied with resolution",
    agent_goals="Identify root causes of system issues and develop robust preventative measures",
    l2_summary="Throughout this 40-step investigation, I conducted a systematic root cause analysis of escalating system error rates, progressing from symptom identification to fundamental cause discovery through a methodical elimination process rather than relying on assumptions or intuition. My analytical approach began by quantifying the precise deviation from normal behavior—4.3% error rate versus 0.5% historical baseline—and establishing a structured investigation framework covering code deployments, infrastructure changes, and external dependencies. Pattern analysis revealed 83% of errors concentrating in the data processing pipeline, leading to a targeted investigation of recent modifications in that subsystem. Rather than making assumptions about the cause, I created isolated test environments for each change and empirically determined that errors only reproduced when the new data enrichment service was enabled—establishing a clear correlation through controlled testing. Deep technical analysis then revealed the specific failure mechanism: a race condition in concurrent request handling that manifested probabilistically based on request overlap timing, explaining why the issue had become apparent only with recent traffic growth increasing concurrency levels. To validate this root cause determination, I developed a minimal reproduction case that triggered the failure deterministically, providing conclusive evidence of the underlying mechanism. The resolution phase demonstrated my analytical thoroughness through three distinct components: an immediate technical fix addressing the specific race condition, broader architectural improvements preventing similar issues across the system, and new testing protocols specifically designed to detect concurrency-related edge cases—which had been a blind spot in our previous quality assurance methodology. Post-implementation monitoring confirmed error rates returned to baseline levels, and my comprehensive post-mortem documentation established both how the defect had originally escaped detection and how the newly developed testing protocols would prevent similar issues system-wide. This progression demonstrates my analytical strengths in quantifying problems precisely, establishing structured investigation frameworks, using controlled testing to establish causation, developing deterministic reproduction cases, implementing multi-level solutions, and creating preventative measures based on root cause understanding.",
)

# Example 7: Analyzer conducting longitudinal trend analysis
example7 = dspy.Example(
    agent_role="Analyzer",
    l1_summaries_context="""
    - Step 33, Consolidated Summary: Began longitudinal analysis of community growth patterns over the past two years. Initial data gathering showed overall growth but with significant variance across different community segments. Started categorizing growth vectors and participation patterns.
    - Step 43, Consolidated Summary: Developed quantitative metrics for community engagement quality beyond simple membership counts. Analysis showed interesting patterns: newer sub-communities showed rapid early growth but 68% experienced sharp decline in engagement after 4-6 months, while established communities maintained more stable engagement despite slower growth.
    - Step 53, Consolidated Summary: Investigated factors correlating with community longevity. Found three significant predictors: regular contribution from at least 5 core members (p<0.01), diversity of discussion topics (p<0.01), and consistent but not excessive moderation activities (p<0.05). Developed regression model incorporating these factors.
    - Step 63, Consolidated Summary: Applied predictive model to current early-stage communities to identify those at risk of premature decline. Model successfully identified 7 communities showing early warning signs despite currently strong growth metrics. Validated predictions against historical data with 83% accuracy.
    - Step 73, Consolidated Summary: Developed evidence-based intervention framework for at-risk communities based on identified success factors. Framework included specific recommendations for core member engagement, topic diversification strategies, and optimal moderation approaches. Began controlled trial of interventions with the 7 identified at-risk communities.
    """,
    overall_mood_trend="Analytically curious throughout, becoming increasingly confident as patterns emerged from data",
    agent_goals="Understand complex social system dynamics through rigorous statistical analysis",
    l2_summary="Throughout this 40-step analysis project, I conducted a comprehensive longitudinal study of community growth dynamics, progressing from basic descriptive statistics to sophisticated predictive modeling that revealed non-obvious patterns in social system behavior. My analytical process began by establishing a structured framework for quantifying community growth vectors and participation patterns, moving beyond simplistic membership counts to develop nuanced engagement quality metrics. This methodical approach revealed a statistically significant pattern that had previously gone undetected: 68% of rapidly growing new sub-communities experienced precipitous engagement decline after 4-6 months despite initially promising metrics, while more established communities maintained stable engagement levels despite slower growth trajectories. Through rigorous statistical analysis including multivariate regression and significance testing, I identified three specific predictors of community longevity with quantified statistical significance: regular contribution from at least 5 core members (p<0.01), topic diversity as measured by conversational entropy metrics (p<0.01), and balanced moderation activity within defined thresholds (p<0.05). The analytical value of these insights was demonstrated through development of a predictive model achieving 83% accuracy when validated against historical data, which successfully identified 7 currently growing communities displaying subtle indicators of future decline despite their superficially strong engagement metrics. Rather than simply documenting these patterns, I translated analytical insights into practical application by developing an evidence-based intervention framework with specific, quantitatively-supported recommendations addressing core member engagement strategies, topic diversification techniques, and optimal moderation approaches. The implementation of a controlled trial applying these interventions to identified at-risk communities represents the culmination of the analytical process—moving from observation to understanding to prediction to action based on rigorous statistical methodology. This progression demonstrates my analytical strengths in developing nuanced metrics beyond obvious surface measures, identifying non-intuitive patterns through statistical analysis, creating validated predictive models, and translating complex statistical insights into practical, actionable recommendations.",
)

# Compile all examples into a list for optimization
analyzer_l2_examples = [example1, example2, example3, example4, example5, example6, example7]
