# src/agents/graphs/basic_agent_graph.py
"""
Defines the basic LangGraph structure for an agent's turn.
"""
import logging
import re  # Add import for regular expressions
from typing import Dict, Any, TypedDict, Annotated, List, Tuple, Optional
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages # Although not used yet, good practice
from src.infra.llm_client import generate_text, analyze_sentiment # Import the LLM generation function and sentiment analysis function
from collections import deque

logger = logging.getLogger(__name__)

# Define the state the graph will operate on during a single agent turn
class AgentTurnState(TypedDict):
    """Represents the state passed into and modified by the agent's graph turn."""
    agent_id: str
    current_state: Dict[str, Any] # The agent's full state dictionary
    simulation_step: int          # The current step number from the simulation
    previous_thought: str | None  # The thought from the *last* turn
    environment_perception: Dict[str, Any] # Perception data from the environment
    memory_history_list: List[Tuple[int, str, str]] # NEW field for history list
    turn_sentiment_score: int     # NEW field for aggregated sentiment score
    llm_thought: str | None       # The thought generated by the LLM
    broadcast_message: str | None # The message to broadcast this turn
    # Add other turn-specific info if needed later (e.g., perceived environment)

    # Output field: The updated state after the turn
    updated_state: Dict[str, Any]

# --- Node Functions ---

def analyze_perception_sentiment_node(state: AgentTurnState) -> Dict[str, Any]:
    """
    Analyzes the sentiment of perceived broadcasts from the previous step.
    Calculates an aggregated sentiment score for the turn.
    """
    agent_id = state['agent_id']
    sim_step = state['simulation_step']
    perception = state.get('environment_perception', {})
    perceived_broadcasts = perception.get('broadcasts', [])
    logger.debug(f"Node 'analyze_perception_sentiment_node' executing for agent {agent_id} at step {sim_step}")

    total_sentiment_score = 0
    analyzed_count = 0

    if not perceived_broadcasts:
        logger.debug("  No broadcasts perceived, sentiment score remains 0.")
        return {"turn_sentiment_score": 0}

    for msg in perceived_broadcasts:
        sender_id = msg.get('sender_id', 'unknown')
        message = msg.get('message', None)

        # Optional: Skip analyzing own messages if they are included in perception
        # if sender_id == agent_id: continue

        if message:
            sentiment = analyze_sentiment(message) # Use the new utility function
            if sentiment == 'positive':
                total_sentiment_score += 1
                analyzed_count += 1
            elif sentiment == 'negative':
                total_sentiment_score -= 1
                analyzed_count += 1
            elif sentiment == 'neutral':
                analyzed_count += 1 # Count neutral messages but don't change score
            # else: sentiment is None (error occurred), do nothing

    logger.info(f"Agent {agent_id}: Aggregated sentiment score from {analyzed_count} perceived messages: {total_sentiment_score}")
    # Return the calculated score to be added to the graph state
    return {"turn_sentiment_score": total_sentiment_score}

def generate_thought_node(state: AgentTurnState) -> Dict[str, Any]:
    """
    Node that calls the LLM to generate a 'thought' and potentially
    a 'broadcast message' based on context, including recent memory history.
    """
    agent_id = state['agent_id']
    current_state = state['current_state']
    sim_step = state['simulation_step']
    # Retrieve the previous thought passed into the graph state
    prev_thought = state.get('previous_thought', None)
    # Retrieve environment perception
    perception = state.get('environment_perception', {})
    other_agents = perception.get('other_agent_ids', [])
    # Get perceived broadcasts
    perceived_broadcasts = perception.get('broadcasts', [])
    # --- Get Memory History ---
    memory_history = state.get('memory_history_list', []) # Get history list
    # --- End Get ---
    # --- Get Sentiment Score ---
    sentiment_score = state.get('turn_sentiment_score', 0) # Get score from previous node
    # --- End Get ---

    logger.debug(f"Node 'generate_thought_node' executing for agent {agent_id} at step {sim_step}")
    logger.debug(f"  Overall sentiment score from perceived messages: {sentiment_score}") # Log score
    logger.debug(f"  Perceived other agent IDs: {other_agents}")
    if perceived_broadcasts: 
        logger.debug(f"  Perceived broadcasts from previous step:")
        for msg in perceived_broadcasts:
            logger.debug(f"    - From {msg.get('sender_id', 'unknown')}: {msg.get('message', '')}")
    if memory_history: 
        logger.debug(f"  Using memory history (last {len(memory_history)} events): {memory_history}") # Log history
    if prev_thought:
        logger.debug(f"  Using previous thought: '{prev_thought}'")

    # --- Update Prompt Engineering ---
    agent_name = current_state.get('name', agent_id) # Use name if available
    step_count = current_state.get('step_counter', 0)
    current_mood = current_state.get('mood', 'neutral') # Get current mood for context

    prompt_lines = [
        f"You are {agent_name}, an AI agent in a simulation.",
        f"Current simulation step: {sim_step}.",
        f"Your current mood is: {current_mood}.", # Include current mood
        f"You have taken {step_count} steps so far."
    ]
    
    if other_agents:
        prompt_lines.append(f"Other agents present: {', '.join(other_agents)}.")
    else:
        prompt_lines.append("You are currently alone.")
    
    # --- Add Memory History to Context ---
    if memory_history:
        prompt_lines.append("\nYour Recent Memory (Past Events):") # Add section header
        for mem_step, mem_type, mem_content in reversed(memory_history): # Show newest first
            if mem_type == 'thought':
                prompt_lines.append(f"  - Step {mem_step}: You thought: \"{mem_content}\"")
            elif mem_type == 'broadcast_sent':
                prompt_lines.append(f"  - Step {mem_step}: You broadcasted: \"{mem_content}\"")
            elif mem_type == 'broadcast_perceived': # Add case for perceived broadcasts
                # Content already includes sender: "sender_id: \"message\""
                prompt_lines.append(f"  - Step {mem_step}: You perceived: {mem_content}")
    # --- End Add Memory ---

    # --- Add Perceived Broadcasts from Previous Step ---
    if perceived_broadcasts:
        prompt_lines.append("\nMessages Broadcast by Others in Previous Step:") # Add section header
        for msg in perceived_broadcasts:
            sender = msg.get('sender_id', 'unknown')
            message = msg.get('message', '')
            # Optional: Filter out self-broadcasts if they are included in perception
            # if sender == agent_id: continue
            prompt_lines.append(f"  - {sender} said: \"{message}\"")
    # --- End Add ---
    
    # --- Add Sentiment Context ---
    prompt_lines.append(f"\nThe overall sentiment of messages you perceived last step was: {sentiment_score} (positive > 0, negative < 0, neutral = 0).")
    # --- End Add ---
    
    if prev_thought:
        prompt_lines.append(f"\nYour previous thought: \"{prev_thought}\"")

    # --- Instruction for LLM ---
    prompt_lines.extend([
        "\nInstructions:",
        "1. First, state your internal thought (1 brief sentence), considering your mood and the sentiment of recent messages. Start with 'Thought:'.",
        "2. Second, if you want to say something to the other agents (or broadcast to the void if alone), state a short message (1 brief sentence). Start with 'Broadcast:'. If you don't want to broadcast, just write 'Broadcast: None'.",
        "\nOutput:" # Signal for the LLM to start its response
    ])

    prompt = "\n".join(prompt_lines)
    # --- End Prompt Engineering ---

    # Call the LLM with mistral:latest model which is available on the system
    # Using a slightly higher temperature for more creative responses
    llm_output = generate_text(prompt, model="mistral:latest", temperature=0.75) 

    # --- Parse LLM Output ---
    thought = None
    broadcast = None
    if llm_output:
        llm_output = llm_output.strip() # Clean whitespace
        try:
            # Regex to find "Thought: (content)" - capture content, handle multiline thoughts
            thought_match = re.search(r"Thought:\s*(.*?)(?=\n\s*Broadcast:|\Z)", llm_output, re.DOTALL | re.IGNORECASE)
            if thought_match:
                thought = thought_match.group(1).strip()

            # Regex to find "Broadcast: (content)" - capture content, handle multiline broadcasts
            broadcast_match = re.search(r"Broadcast:\s*(.*)", llm_output, re.DOTALL | re.IGNORECASE)
            if broadcast_match:
                broadcast_content = broadcast_match.group(1).strip()
                # Check if the broadcast content is explicitly "None"
                if broadcast_content.lower() != 'none':
                    broadcast = broadcast_content
                # If 'none' was intended, broadcast remains None

            # Fallback if regex fails but output exists
            if not thought and not broadcast and llm_output:
                logger.warning(f"Agent {agent_id}: Could not parse Thought/Broadcast via regex. Using first line as thought. Output: '{llm_output}'")
                thought = llm_output.split('\n')[0].strip() # Take first line as thought

        except Exception as e:
            logger.error(f"Agent {agent_id}: Exception during LLM output parsing '{llm_output}': {e}", exc_info=True)
            thought = "[parsing exception]" # Fallback thought
            broadcast = None # Ensure broadcast is None on error
    # --- End Parse LLM Output ---

    if thought:
        logger.info(f"Agent {agent_id} generated thought: '{thought}'")
    else:
        # Ensure thought has a fallback if parsing completely fails
        thought = "[failed to generate or parse thought]"
        logger.warning(f"Agent {agent_id} ended node with no valid thought.")

    if broadcast:
        logger.info(f"Agent {agent_id} generated broadcast: '{broadcast}'")

    # Return both thought and broadcast message for the graph state
    return {
        "llm_thought": thought,
        "broadcast_message": broadcast # Will be None if not generated or explicitly "None"
    }

def update_counter_and_state(state: AgentTurnState) -> Dict[str, Any]:
    """
    Increments step_counter, updates mood based on sentiment, stores
    thought/broadcast, and updates memory history to include own actions
    AND perceived broadcasts from the previous step.
    """
    agent_id = state['agent_id']
    sim_step = state['simulation_step'] # Current step number
    thought = state.get('llm_thought', None)
    # Retrieve the broadcast message generated by the previous node
    broadcast = state.get('broadcast_message', None)
    # Get the broadcasts perceived at the START of this turn (from the previous step)
    perceived_broadcasts = state.get('environment_perception', {}).get('broadcasts', []) # Get perceived broadcasts
    # --- Get Sentiment Score ---
    sentiment_score = state.get('turn_sentiment_score', 0) # Get score
    # --- End Get ---

    logger.debug(f"Node 'update_counter_and_state' executing for agent {agent_id}")
    logger.debug(f"  Using sentiment score {sentiment_score} to update mood.") # Log score usage
    if thought: logger.debug(f"  Processing thought: '{thought}'")
    if broadcast: logger.debug(f"  Processing broadcast: '{broadcast}'")

    current_agent_state = state['current_state'].copy() # Get a copy of the agent's main state
    try:
        # Increment step counter
        current_count = current_agent_state.get('step_counter', 0)
        new_count = current_count + 1
        current_agent_state['step_counter'] = new_count

        # --- Update Mood Based on Sentiment ---
        current_mood = current_agent_state.get('mood', 'neutral')
        new_mood = current_mood # Default to current mood
        # Simple mood logic: positive score -> happy, negative -> unhappy, neutral -> neutral
        # More complex logic could involve thresholds, decay, etc.
        if sentiment_score > 0:
            new_mood = 'happy'
        elif sentiment_score < 0:
            new_mood = 'unhappy'
        else: # sentiment_score == 0
            # Optional: Tend towards neutral if score is 0, or keep current mood
            new_mood = 'neutral'

        if new_mood != current_mood:
            logger.info(f"Agent {agent_id} mood changed from '{current_mood}' to '{new_mood}' based on sentiment score {sentiment_score}.")
            current_agent_state['mood'] = new_mood
        else:
            logger.debug(f"Agent {agent_id} mood remains '{current_mood}'.")
        # --- End Update Mood ---

        # Store the generated thought and broadcast into the agent's main state
        if thought:
            current_agent_state['last_thought'] = thought
        else:
            # Handle case where thought is None or empty if needed
            current_agent_state['last_thought'] = "[no thought generated]"
            
        # Store the broadcast message (can be None if no broadcast)
        current_agent_state['last_broadcast'] = broadcast

        # --- Update Memory History ---
        # Retrieve the history list, convert to deque, append, convert back to list
        memory_list = current_agent_state.get('memory_history', [])
        # Use the same maxlen as defined in Agent.__init__
        memory_deque = deque(memory_list, maxlen=5)

        # 1. Add perceived broadcasts from the *previous* step to memory
        # Note: The step number associated here is the step they were *perceived* (current step),
        # even though they were generated in the previous step.
        if perceived_broadcasts:
            logger.debug(f"  Adding {len(perceived_broadcasts)} perceived broadcasts to memory.")
            for msg in perceived_broadcasts:
                sender = msg.get('sender_id', 'unknown')
                message = msg.get('message', '')
                # Optional: Filter out perceiving own message if needed
                # if sender == agent_id: continue
                memory_deque.append((sim_step, 'broadcast_perceived', f"{sender}: \"{message}\"")) # Add perceived

        # 2. Add own thought and broadcast from the *current* step
        if thought:
            memory_deque.append((sim_step, 'thought', thought))
        if broadcast:
            memory_deque.append((sim_step, 'broadcast_sent', broadcast))

        # Store the updated history back into the state dictionary as a list
        current_agent_state['memory_history'] = list(memory_deque)
        logger.debug(f"  Updated memory history (length {len(memory_deque)}): {list(memory_deque)}")
        # --- End Update Memory ---

        logger.debug(f"Agent {agent_id} step_counter incremented to {new_count}")
    except Exception as e:
        logger.error(f"Error in update_counter_and_state for agent {agent_id}: {e}")
        # Return the original state if error occurs during update
        return {"updated_state": state['current_state']}

    # Return the modified agent state dictionary to be placed in the 'updated_state' field
    # This updated_state will then be used to overwrite the agent's main state
    return {"updated_state": current_agent_state}


# --- Graph Definition ---

def create_basic_agent_graph():
    """
    Builds the agent turn graph including sentiment analysis,
    thought generation, and state update nodes.
    """
    workflow = StateGraph(AgentTurnState)

    # Add the nodes
    workflow.add_node("analyze_sentiment", analyze_perception_sentiment_node) # NEW
    workflow.add_node("generate_thought", generate_thought_node)
    workflow.add_node("update_state", update_counter_and_state) # Renamed for clarity

    # Set the entry point to sentiment analysis
    workflow.set_entry_point("analyze_sentiment") # NEW Entry Point

    # Define the flow: analyze_sentiment -> generate_thought -> update_state -> END
    workflow.add_edge("analyze_sentiment", "generate_thought") # NEW Edge
    workflow.add_edge("generate_thought", "update_state")
    workflow.add_edge("update_state", END)

    # Compile the graph
    graph = workflow.compile()
    logger.info("Agent graph with sentiment analysis compiled successfully.")
    return graph

# --- Pre-compile graph for potential reuse ---
# This ensures the graph is compiled only once when the module is imported
basic_agent_graph_compiled = create_basic_agent_graph() 